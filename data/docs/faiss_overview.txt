FAISS (Facebook AI Similarity Search) is an open-source library developed by Meta (formerly Facebook) for efficient similarity search and clustering of dense vectors.  It is designed to handle massive datasets—ranging from millions to billions of high-dimensional vectors—making it ideal for applications like recommendation systems, image retrieval, natural language processing, and content moderation. 

Key Features
High Performance: Optimized for speed and memory efficiency using advanced algorithms like Product Quantization (PQ), Inverted-File Indexes (IVF), HNSW, and NSG graphs. 
GPU Acceleration: Many algorithms are implemented on GPU using CUDA, enabling fast approximate nearest neighbor (ANN) search at scale. 
Flexible Indexing: Supports multiple indexing methods including brute-force (IndexFlatL2), compressed indices, and graph-based approaches. 
Vector Compression: Includes lossy compression via vector quantization, allowing trade-offs between accuracy and storage size. 
Python & C++ Interfaces: Full Python wrappers (NumPy compatible) with seamless CPU/GPU support. 
Core Assumptions: Uses FP32 as the primary data type; supports BF16 and FP16; prefers batch queries over single queries. 
Use Cases
Recommender Systems: Find similar items based on embedding vectors. 
Image & Video Search: Identify visually similar media using deep learning embeddings. 
Text Retrieval: Semantic search over document or sentence embeddings. 
Data Deduplication: Detect duplicate or near-duplicate data (e.g., images).
Vector Databases: Serves as a foundational component in systems like Milvus, OpenSearch, and Vearch. 
Technical Highlights
Primary Distance Metrics: Euclidean (L2) and inner product (dot product); limited support for Manhattan and Lp distances.
Built-in Tools: Includes k-means clustering, PCA, random rotation, and data deduplication.
Stable Release: v1.12.0 (August 12, 2025). 
License: MIT License.
Repository: github.com/facebookresearch/faiss
FAISS is widely regarded as a benchmark standard in similarity search and is often used as a baseline in large-scale ANN competitions like NeurIPS and Big ANN

vectors and enable fast similarity queries.  The choice of index determines the trade-offs between speed, memory usage, and accuracy. 

Core Index Types
1. Flat Index (Exact Search)
Description: Brute-force search that computes distances to all vectors. 
Accuracy: 100% (exact results).
Use Case: Small datasets (<100K vectors). 
Variants:
IndexFlatL2: Uses Euclidean (L2) distance.
IndexFlatIP: Uses inner product (cosine similarity on normalized vectors). 

FAISS
library for similarity search
Wikipedia
faiss.ai
2. Inverted File Index (IVF)
Mechanism: Partitions the vector space into nlist clusters using k-means. 
Search Process:
Find the nprobe closest clusters to the query.
Search only within those clusters.
Speed vs Accuracy: Controlled by nprobe (higher = slower but more accurate).
Base Index: Typically IndexIVFFlat, but can be combined with compression. 

FAISS IVF index explained





3. Hierarchical Navigable Small World (HNSW)
Structure: Multi-layered graph where nodes represent vectors. 
Search: Starts at the top layer (coarse view), navigates down to finer layers. 
Advantages: Very fast and accurate; no training required. 
Memory: Higher than IVF but excellent performance.
Variant: IndexHNSWFlat (supports compression via IndexHNSWPQ). 

HNSW algorithm explained





4. Product Quantization (PQ)
Concept: Compresses vectors by splitting them into subvectors and quantizing each. 
Storage: Each subvector represented by a codebook index (e.g., 8 bits instead of 32-bit float). 
Search: Distance computed in compressed domain (faster and memory-efficient). 
Trade-off: Slight accuracy loss for significant speed and size gains.

Product Quantization in FAISS

5. IVF + PQ (IndexIVFPQ)
Hybrid Approach:
IVF partitions data into clusters.
PQ compresses vectors within each cluster.
Efficiency: Only decompress and search in nprobe clusters.
Ideal For: Large-scale datasets (millions to billions of vectors). 
Example: index = faiss.IndexIVFPQ(quantizer, d=128, nlist=100, M=16, nbits=8)

FAISS IVFPQ tuning parameters site:reddit.com





Distance Metrics
L2 (Euclidean): Default for IndexFlatL2, IVF, etc.
Inner Product (IP): Used for cosine similarity (vectors should be normalized). 
Limited Support: L1 (Manhattan), Linf (Chebyshev).
Binary Metrics: Hamming distance via IndexLSH. 
GPU Acceleration
FAISS supports CUDA for significant speedups.
GPU versions mirror CPU indexes (e.g., GpuIndexFlatL2, GpuIndexIVFPQ).
Multi-GPU and CPU-GPU interoperability supported. 